{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This notebook trains a CNN on Mnist data set with tensorflow\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "## Import data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist= input_data.read_data_sets('/tmp/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Placeholder for input data\n",
    "\n",
    "X=tf.placeholder(tf.float32,shape=[None,28,28,1],name='X')\n",
    "Y=tf.placeholder(tf.int64,name='Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Creat a place to save the log files, which can be used for visualization in the tensorboard\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now=datetime.utcnow().strftime('%Y%m%d%H%M%S')\n",
    "root_logdir='CNN_Mnist2'\n",
    "logdir='{}/run-{}/'.format(root_logdir,now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define convolution layer\n",
    "def con_layer(X,size_out,name):\n",
    "    with tf.name_scope(name):\n",
    "        size_in=int(X.get_shape()[3])\n",
    "        w=tf.Variable(tf.truncated_normal((3, 3, size_in, size_out), stddev=0.1),name='weights')\n",
    "        b=tf.Variable(tf.zeros(size_out),name='bias')\n",
    "        conv=tf.nn.conv2d(X,w,strides=[1,2,2,1],padding='SAME')\n",
    "        act = tf.nn.relu(conv + b)\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        ##so we can visualize the distributions of activations coming off this layer\n",
    "        tf.summary.histogram(\"activations\", act)\n",
    "        return act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Max_pooling layer\n",
    "def pooling(X,height,width,name):\n",
    "    with tf.name_scope(name):    \n",
    "        return tf.nn.max_pool(X,ksize=[1,height,width,1],strides=[1,2,2,1],padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Fully_connected layer\n",
    "def fully_connect(X,n_neurons,name,activation=None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs=int(X.get_shape()[1])\n",
    "        stddev=2/np.sqrt(n_inputs)\n",
    "        w=tf.Variable(tf.truncated_normal([n_inputs,n_neurons],stddev=stddev),name='weights')\n",
    "        b=tf.Variable(tf.constant(0.1,shape=(n_neurons,)),name='bias')\n",
    "        z=tf.matmul(X,w)+b\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        if activation=='relu':\n",
    "            tf.summary.histogram(\"activations\", tf.nn.relu(z))\n",
    "            return tf.nn.relu(z)\n",
    "        else:\n",
    "            return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the CNN\n",
    "with tf.name_scope('CNN'):\n",
    "    hidden1=con_layer(X,12,'Conv_1')\n",
    "    hidden2=pooling(hidden1,3,3,'Pooling_1')\n",
    "    hidden3=con_layer(hidden2,36,'Conv_2')\n",
    "    hidden4=con_layer(hidden3,64,'Conv_3')\n",
    "    fc_input=tf.reshape(hidden4,[-1,int(hidden4.get_shape()[1])*int(hidden4.get_shape()[2])*int(hidden4.get_shape()[3])])\n",
    "    hidden5=fully_connect(fc_input,84,'fc_1',activation='relu')\n",
    "    hidden6=fully_connect(hidden5,10,'fc_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Define loss function\n",
    "\n",
    "with tf.name_scope('Loss'):\n",
    "    entropy=tf.nn.sparse_softmax_cross_entropy_with_logits(labels=Y,logits=hidden6)\n",
    "    loss=tf.reduce_mean(entropy,name='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Define optimizer and training step\n",
    "with tf.name_scope('Train'):\n",
    "    optimizer=tf.train.AdamOptimizer(learning_rate=0.01,epsilon=0.1)\n",
    "    train_op=optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Define evaluation metrics\n",
    "with tf.name_scope('eval'):\n",
    "    correct=tf.nn.in_top_k(hidden6,Y,1)\n",
    "    accuracy=tf.reduce_mean(tf.cast(correct,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Creat summary protocol buffer for visualization in the tensorboard\n",
    "loss_summary=tf.summary.scalar('Loss',loss)\n",
    "acc_train_summary=tf.summary.scalar('train_acc',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged = tf.summary.merge_all()\n",
    "train_file_writer=tf.summary.FileWriter(logdir+'/train', tf.get_default_graph())\n",
    "test_file_writer=tf.summary.FileWriter(logdir+'/test', tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_test_summary=tf.summary.scalar('test_acc',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## t\n",
    "saver=tf.train.Saver()\n",
    "init=tf.global_variables_initializer()\n",
    "n_epochs=500\n",
    "batch_size=50\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples//batch_size):\n",
    "            x_batch, y_batch=mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_op,feed_dict={X:np.reshape(x_batch,(-1,28,28,1)),Y:y_batch})\n",
    "        summary_str_train=merged.eval(feed_dict={X:np.reshape(x_batch,(-1,28,28,1)),Y:y_batch})\n",
    "        summary_str_test=acc_test_summary.eval(feed_dict={X:np.reshape(mnist.test.images,(-1,28,28,1)),Y:mnist.test.labels})\n",
    "        train_file_writer.add_summary(summary_str_train,epoch)\n",
    "        test_file_writer.add_summary(summary_str_test,epoch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_file_writer.close()\n",
    "test_file_writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
